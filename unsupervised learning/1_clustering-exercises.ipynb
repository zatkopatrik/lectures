{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn library has an implementation of the k-means algorithm. Let’s apply it to a set of randomly generated blobs, whose labels we throw away. \n",
    "\n",
    "make_blobs() function generates a data set for clustering. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n",
    "\n",
    "__TO DO__: Find out how many instances with how many features were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X,y = make_blobs(random_state=42) \n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: Plot the points X with a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example you can guess the number of clusters. Let’s see if the k-means algorithm can recover these clusters. \n",
    "\n",
    "__TO DO__: Import KMeans from sklearn.cluster and create the instance of the k-means model by giving it the number of clusters 3 as a hyperparameter. Fit the model to your dataset X. Notice that we do not feed labels y into the model. Help yourself with the examples from the documentation\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: assign centroids to the variable centroids and print it. Use KMeans model's attribute cluster_centers_. \n",
    "\n",
    "- The centroids are important because they are what enables KMeans to assign new, previously unseen points to the existing clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: assign predicted class labels to the variable _labels_ and print it. Use KMeans model's attribute labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: Plot the points X with a scatter plot with colors equal to labels. The pre-filled line plots the centroids with a red dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "plt.scatter(centroids[:,0], centroids[:,1], s=100, color=\"red\"); # Show the centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: return KMeans' performance measure inertia  with an attribute inertia_\n",
    "\n",
    "- inertia = Sum of squared distances of samples to their closest cluster center. The lower the inertia the better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the number of clusters where inertia does not decrease significantly anymore = Elbow rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for k in range(1, 15):\n",
    "    km = KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "plt.plot(range(1, 15), inertia, marker='s')\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('$J(C_k)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: Use the .predict() method of model to predict the cluster labels of new_points. Assign them to _new_labels_ variable and print them. Notice that KMeans can assign previously unseen points to the clusters it has already found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_points = np.array([[-4, 5], [-6, -2.5], [4, -2.5], [0, 10]])\n",
    "###\n",
    "print(new_labels)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1], c=labels)\n",
    "plt.scatter(new_points[:,0], new_points[:,1], c=new_labels, marker = 'X', s = 300);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling, numerical variables\n",
    "\n",
    "Read the data set below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python\n",
    "customers = pd.read_csv('data/Mall_Customers.csv')\n",
    "customers.set_index('CustomerID', inplace = True)\n",
    "customers['Annual Income (k$)'] = customers['Annual Income (k$)']*1000\n",
    "customers.columns = ['gender', 'age', 'annual_income_$', 'spending_score']\n",
    "display(customers.head(5))\n",
    "print(f'\\nShape of customers data set: {customers.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annual income has a very different scale than other two numerical features. \n",
    "\n",
    "For distance based methods scaling helps if the features have very different scales. We will scale here all numerical features with StandardScaler(). It standardizes features by removing the mean and scales to unit variance\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = customers.select_dtypes(exclude='object').columns # get numerical columns\n",
    "customers[num_cols] = scaler.fit_transform(customers[num_cols]) # apply scaler to numerical columns\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: fit the KMeans() model to the customers dataset. You will get an error. Don't worry, this one is on purpose. Proceed with the next cell after the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem here? We have to transform non-numerical columns to numerical ones as it is not possible to calculate a distance between non-numerical features. We will use LabelEncoder for all the non numerical columns in a generic way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select only non-numerical columns with select_dtypes() method\n",
    "non_num_cols = customers.select_dtypes(include='object').columns\n",
    "\n",
    "# use LabelEncoder from scikit learn preprocessing module to encode values from non-numerical columnns to numerical\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in non_num_cols:\n",
    "    customers[col + '_encoded'] = le.fit_transform(customers[non_num_cols])\n",
    "    \n",
    "# drop non-numerical columns\n",
    "customers.drop(columns = non_num_cols, inplace=True)\n",
    "display(customers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: Fit the KMeans model again to the customers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "Density-Based Spatial Clustering of Applications with Noise. The algorithm finds core samples of high density and expands clusters from them. It is good for data which contain clusters of similar density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset and plot it. Clearly there should be two clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_moons, y_moons = datasets.make_moons(n_samples=1000, noise=0.05,random_state=42)\n",
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=y_moons);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans fails to find appropriate clusters as it searches for convex shapes. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_labels = KMeans(2).fit(x_moons).labels_\n",
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=kmeans_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: \n",
    "- Initiate DBSCAN instance with eps=0.05 and min_samples=5 and assign it to _dbscan_ variable. \n",
    "- Fit the model to x_moons.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: \n",
    "- Return labels of dbscan with an attribute labels_ and assign the labels to _dbscan_labels_ variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are labels == -1. These denote outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(dbscan_labels, return_counts=True)\n",
    "display(pd.DataFrame(np.asarray((unique, counts)).T, columns = ['labels', 'frequency']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters and outliers on a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_moons[:, 0], x_moons[:, 1], c=dbscan_labels, alpha=0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TO DO__: indices of the core instances are available in the core_sample_indices_ attribute of DBSCAN. Assign them to comps_idx variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core instances are stored in the components_ attribute. Below we create a mask for indices which are core instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dbscan.components_)\n",
    "\n",
    "comps_idx_boolean = np.array([(i in comps_idx) for i in range(len(x_moons))]) # this creates a boolean mask for core instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_moons[comps_idx_boolean, 0], x_moons[comps_idx_boolean, 1], c='r', alpha=0.3, label='core')\n",
    "plt.scatter(x_moons[~comps_idx_boolean, 0], x_moons[~comps_idx_boolean, 1], c='b', alpha=0.6, linewidths = 0.1, label='outliers')\n",
    "plt.legend()\n",
    "plt.title('Core vs non-core instances');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DBSCAN clustering did not return expected results. Let's try different eps and min_samples\n",
    "\n",
    "__TO DO__: fit DBSCAN to x_moons again but now with eps=0.2 and min_samples=5. Plot the resulting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice that DBSCAN class does not have .predict() method although it has a fit_predict() method. It cannot predict a cluster for a new instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DBSCAN' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-34a0c9365b27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdbscan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_moons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DBSCAN' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "dbscan.predict(x_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
